{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "IRIS_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FPoydbd3LVn"
      },
      "source": [
        "IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNSO9HiaAlN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9688e3-9161-4c66-e087-8cd222e484bb"
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install pandas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (51.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvCDlSEZZ86d"
      },
      "source": [
        "%matplotlib inline \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical # Function to convert labels to one-hot encoding\n",
        "import pandas as pd  \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.datasets import load_iris  # Function for loading the Iris dataset\n",
        "from sklearn.model_selection import train_test_split # Function for splitting the dataset"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43CAmb0AZ86d"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32CeQi7UZ86e"
      },
      "source": [
        "# Load the dataset and return to the defined variable \n",
        "dataset = load_iris()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bw_vBZqZ86e",
        "outputId": "8027f345-39b5-43df-f8be-c47ce4f67abf"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.6, 1.4, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/iris.csv'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkI6pNUI76W8"
      },
      "source": [
        "Here we have a dictionary with key data and their corresponding values.\n",
        "\n",
        "We have the target keys and target values.\n",
        "\n",
        "In the above dataset we have three keys - data ,target , and target_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Z9JcGvbS8u"
      },
      "source": [
        "To access values please type dictionaray and its keys\n",
        "To access the values of keys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzwqY0FVbhxh",
        "outputId": "b8a1f1a2-c354-48bd-d421-aca8f4671677"
      },
      "source": [
        "print(dataset.data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9NpsEVUcBNx"
      },
      "source": [
        "TO GET THE TARGET NAMES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ULLH0vNcGkT",
        "outputId": "d4cca01e-de65-4c5d-f1a1-09f941123cfc"
      },
      "source": [
        "print(dataset.target_names)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9vH8kFVcWKK"
      },
      "source": [
        "We have three target names i.e. classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZT3EinOdAYO",
        "outputId": "13b72df2-bd42-4769-d420-d9fd9d3031e3"
      },
      "source": [
        "print(dataset.target)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClQNKHoac7pW"
      },
      "source": [
        "WE HAVE THREE TARGET VALUES\n",
        "integer representation of predicted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddEG3B0i2aJU",
        "outputId": "2a2b1bf6-175d-46cf-ae4b-64ab35f062f2"
      },
      "source": [
        "# Load iris data into a DataFrame\n",
        "#print(dataset.data)\n",
        "#print(dataset.feature_names)\n",
        "# combine the above two and make a datframe\n",
        "dframe = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "print(dframe)\n",
        "\n",
        "# datadrame is 2d data strcture\n",
        "# teh data is alligned in in tabular fashion in rows andc olumns"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                  5.1               3.5                1.4               0.2\n",
            "1                  4.9               3.0                1.4               0.2\n",
            "2                  4.7               3.2                1.3               0.2\n",
            "3                  4.6               3.1                1.5               0.2\n",
            "4                  5.0               3.6                1.4               0.2\n",
            "..                 ...               ...                ...               ...\n",
            "145                6.7               3.0                5.2               2.3\n",
            "146                6.3               2.5                5.0               1.9\n",
            "147                6.5               3.0                5.2               2.0\n",
            "148                6.2               3.4                5.4               2.3\n",
            "149                5.9               3.0                5.1               1.8\n",
            "\n",
            "[150 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5VDqygqzw8"
      },
      "source": [
        "The dataset is small ie. 150 rows and 4 columns "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmUxO58Sqzml"
      },
      "source": [
        "ADDING LABELS TO THE ABOVE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4sBO6oGZ86f",
        "outputId": "8372e225-177b-4f59-9340-e83a0ba7b9c9"
      },
      "source": [
        "\n",
        "#print(dataset.target)# WE KNOW THAT WE NEED TO USE TARGET SINCE THE DATA HAS THE COLUMMN TARGET\n",
        "#ADDING ONE MORE COLUMNS\n",
        "#NUMERICAL REPRESNETATION OF TARGET\n",
        "dframe['labels'] = dataset.target.astype(int) # Labels are represented as integers\n",
        "print(dframe)\n",
        "# add \"target_label\" column to the dataset and name it \"label\"\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal length (cm)  sepal width (cm)  ...  petal width (cm)  labels\n",
            "0                  5.1               3.5  ...               0.2       0\n",
            "1                  4.9               3.0  ...               0.2       0\n",
            "2                  4.7               3.2  ...               0.2       0\n",
            "3                  4.6               3.1  ...               0.2       0\n",
            "4                  5.0               3.6  ...               0.2       0\n",
            "..                 ...               ...  ...               ...     ...\n",
            "145                6.7               3.0  ...               2.3       2\n",
            "146                6.3               2.5  ...               1.9       2\n",
            "147                6.5               3.0  ...               2.0       2\n",
            "148                6.2               3.4  ...               2.3       2\n",
            "149                5.9               3.0  ...               1.8       2\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK9N1whet3SL"
      },
      "source": [
        "REPRESENTING THE LABELS WITH STRING VALUES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI6vgCnX27rd",
        "outputId": "f7f92b0e-077f-4434-c0f5-4a81c9f8fc28"
      },
      "source": [
        "#STRING REPRESNETATION OF LABELS COLUMN CREATED ABOVE \n",
        "# use of String label\n",
        "dframe['label_names'] = dframe.labels.replace(dict(enumerate(dataset.target_names)))\n",
        "print(dframe)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal length (cm)  sepal width (cm)  ...  labels  label_names\n",
            "0                  5.1               3.5  ...       0       setosa\n",
            "1                  4.9               3.0  ...       0       setosa\n",
            "2                  4.7               3.2  ...       0       setosa\n",
            "3                  4.6               3.1  ...       0       setosa\n",
            "4                  5.0               3.6  ...       0       setosa\n",
            "..                 ...               ...  ...     ...          ...\n",
            "145                6.7               3.0  ...       2    virginica\n",
            "146                6.3               2.5  ...       2    virginica\n",
            "147                6.5               3.0  ...       2    virginica\n",
            "148                6.2               3.4  ...       2    virginica\n",
            "149                5.9               3.0  ...       2    virginica\n",
            "\n",
            "[150 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Xp5KZ4rF2l"
      },
      "source": [
        "A string representation of the above labels has been created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LrP1_tfKZ86f",
        "outputId": "d34748f6-1c8f-4aab-9a23-174eb94ad286"
      },
      "source": [
        "# Prints the 5 first rows/samples of the dataset\n",
        "dframe.head(5)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>labels</th>\n",
              "      <th>label_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  labels  label_names\n",
              "0                5.1               3.5  ...       0       setosa\n",
              "1                4.9               3.0  ...       0       setosa\n",
              "2                4.7               3.2  ...       0       setosa\n",
              "3                4.6               3.1  ...       0       setosa\n",
              "4                5.0               3.6  ...       0       setosa\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag9_85f1Z86g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "93147350-9904-492b-d709-38880cbcb25e"
      },
      "source": [
        "# Generates a short description of the dataset (missing values, mean values, etc.)\n",
        "dframe.describe()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "      <td>0.819232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  ...  petal width (cm)      labels\n",
              "count         150.000000        150.000000  ...        150.000000  150.000000\n",
              "mean            5.843333          3.057333  ...          1.199333    1.000000\n",
              "std             0.828066          0.435866  ...          0.762238    0.819232\n",
              "min             4.300000          2.000000  ...          0.100000    0.000000\n",
              "25%             5.100000          2.800000  ...          0.300000    0.000000\n",
              "50%             5.800000          3.000000  ...          1.300000    1.000000\n",
              "75%             6.400000          3.300000  ...          1.800000    2.000000\n",
              "max             7.900000          4.400000  ...          2.500000    2.000000\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrkl09hm7UsP"
      },
      "source": [
        "There are no missing values since he count of all the columns is 150."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHbQ6ObZ86h"
      },
      "source": [
        "## Train, Validation and Test Sets Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSUAUx5uZ86i",
        "outputId": "495fef1e-7820-4847-a19a-efdc7be5b45c"
      },
      "source": [
        "# Extracting the features and labels from the dataset \n",
        "X = np.asarray(dframe[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
        "Y = np.asarray(dframe['labels'])\n",
        "#WE NEED TO CONVERT DATAFRAME TO NP ARRAY\n",
        "#np.asarray convertes  the dataframe values into the mutimentional numpy array\n",
        "\n",
        "# First we will shuffle the samples\n",
        "#print(X.shape[0])\n",
        "indexes = np.arange(X.shape[0]) # indexes = np.arange(150) # creat an evenly spaced array whose values r ranging from 0 to 150\n",
        "#print(indexes)\n",
        "np.random.shuffle(indexes)#shuffling values to create randomization in the dataset\n",
        "#print(indexes) #array has random value array\n",
        "X = X[indexes,:] # here we r using array to randomize the dataset\n",
        "# we rassign the values according to the new order\n",
        "Y = Y[indexes]\n",
        "\n",
        "# Then, we split our data into train/val/test sets\n",
        "#here we r declaring teh splitting ratio\n",
        "#print(Y.size)\n",
        "train_split = np.int(0.5*Y.size)#150*0.5 = 75\n",
        "val_split = np.int(0.75*Y.size)#0.75*150=112\n",
        "\n",
        "X_train = X[:train_split,:]#rows = :train_split # consider all the rows from 0 to 75 , # columns = : # consider all the columnsn of those rows\n",
        "Y_train = Y[:train_split] # consider all the rows from 0 to 75 in the label column\n",
        "print( \"Size of X_train : \" , X_train.size)# total nummber of values\n",
        "\n",
        "print( \"Shape of X_train : \" , X_train.shape)# shape of the array\n",
        "\n",
        "X_val = X[train_split:val_split,:]# all rows between 75 and 112 ie. 37\n",
        "Y_val = Y[train_split:val_split]\n",
        "print( \"Shape of X_val : \" , X_val.shape)# shape of the array\n",
        "\n",
        "X_test = X[val_split:,:]# all rows from 112 to 149 ie.e 38 rows\n",
        "Y_test = Y[val_split:]\n",
        "print( \"Shape of X_test : \" , X_test.shape)# shape of the array"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of X_train :  300\n",
            "Shape of X_train :  (75, 4)\n",
            "Shape of X_val :  (37, 4)\n",
            "Shape of X_test :  (38, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAsmIMViZ86i"
      },
      "source": [
        "## Data Normalization\n",
        "The goal is to normalize/chnage the values in the NUMERICAL datset between 0 and 1 which disorting the range of values\n",
        "It is required only when the features have very high and differnet ranges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8aTRNXiZ86i",
        "outputId": "e28512c3-9715-4229-fe41-149411c02808"
      },
      "source": [
        "# min-max data normalization\n",
        "print(\"Original Traning Values\")\n",
        "print(X_train[0])# print out the first row of teh X_train\n",
        "x_train_min = X_train.min(axis = 0, keepdims = True)# axis = 0 represnts the rows\n",
        "# it will find the minimum value in a particular row and assihgn it to x_train_min #ask\n",
        "#print(x_train_min)\n",
        "x_train_max = X_train.max(axis = 0, keepdims = True)\n",
        "\n",
        "print(\"--------------------------------------------\")\n",
        "\n",
        "X_train = (X_train - x_train_min)/(x_train_max - x_train_min)\n",
        "X_val = (X_val - x_train_min)/(x_train_max - x_train_min)\n",
        "X_test = (X_test - x_train_min)/(x_train_max - x_train_min)\n",
        "print(\"Standardized Traning Values\")\n",
        "print(X_train[0])\n",
        "\n",
        "#####################################################################################\n",
        "#Activity suggestion:\n",
        "# 1. Change the min-max normalization above by standardization ((X - mean)/(std))\n",
        "# 2. Don't normalize the data and see what happens\n",
        "####################################################################################"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Traning Values\n",
            "[5.6 3.  4.5 1.5]\n",
            "--------------------------------------------\n",
            "Standardized Traning Values\n",
            "[0.38235294 0.4        0.5862069  0.60869565]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "378uyl4HHovA"
      },
      "source": [
        "The orginal value it will changed from 7.1 to 0.77"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haESIaQ3Z86j"
      },
      "source": [
        "## Representing Labels using one-hot-ecoding\n",
        "It is the represntation of categorial values as binary vectors\n",
        "\n",
        "Categorial variable in Y datset have been converted to integer values, each integer values are represnted as a binary value that is all 0 values except the value of integer marked as 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZaIuJw2Z86j",
        "outputId": "561216f1-ec65-4b13-9bcd-b994f90e4d56"
      },
      "source": [
        "k = np.unique(Y).size\n",
        "print('The number of unique labels are:')\n",
        "print(k)\n",
        "#print(Y_oh_train)\n",
        "Y_oh_train = to_categorical(Y_train, k) #converts class vector to binary class matrix \n",
        "# here the categorical variables in Y_train are converted to binary values based on k ie. the unique values in Y label\n",
        "Y_oh_val = to_categorical(Y_val, k)\n",
        "Y_oh_test = to_categorical(Y_test, k)\n",
        "# Displaying the 5 first elemnts\n",
        "print('\\nY_train[:5]:')\n",
        "print(Y_train[:5])\n",
        "print('\\nY_oh_train[:5]=')\n",
        "print(Y_oh_train[:5])\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique labels are:\n",
            "3\n",
            "\n",
            "Y_train[:5]:\n",
            "[1 2 0 1 0]\n",
            "\n",
            "Y_oh_train[:5]=\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdq183taZ86k"
      },
      "source": [
        "## Different Approaches for Defining Neural Networks\n",
        "## METHOD 1\n",
        "### 1. The Sequential API\n",
        "It is a linear stack of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20nbOkXHZ86k",
        "outputId": "34a5cde5-4914-49fb-d260-ce96c9e08125"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "# Passing a list of layers to the constructor\n",
        "model = Sequential([\n",
        "    tf.keras.layers.Dense(20, activation='relu', input_shape=(4,) , name = \"layer1\"), # 5 nodes for layer 1 # FIXED input shape expected shoudl be written\n",
        "    # here we have input_shape=(4,) since we have 4 differnet features to layer 1\n",
        "    tf.keras.layers.Dense(50, activation='relu' , name = \"layer2\"),  # 10 nodes for layer 2\n",
        "    tf.keras.layers.Dense(50, activation='relu' , name = \"layer3\"),  # 10 nodes for layer 3\n",
        "    tf.keras.layers.Dense(3, activation='softmax', name = \"layer4\"), # 3 nodes or neurons for layer 4 #fixed 3 neurons since 3 labels\n",
        "])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# adding layer via add() method\n",
        "# from tf.keras.layers import Dense\n",
        "# model_seq = Sequential ()\n",
        "# model_seq.add(Dense(5, activation = 'relu' , input_shape = (4,1)))\n",
        "# model_seq.add(Dense(10, activation = 'relu' ))\n",
        "# model_seq.add(Dense(3, activation = 'softmax' ))\n",
        "# model_seq.aummary()\n",
        "\n",
        "#n_input*n_node + bias(n_node)\n",
        "# 4*5+5 = 25\n",
        "# 5*10+10 = 60\n",
        "# 10*3 + 3 = 33"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 20)                100       \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 50)                1050      \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "layer4 (Dense)               (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 3,853\n",
            "Trainable params: 3,853\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G0iyp6pjPPk"
      },
      "source": [
        "parameters are to ne trained when u compile the model\n",
        "parameters = (input+1)x output = (4+1)*5 = 25\n",
        "\n",
        "\n",
        "- parameters = (input+1)x output = (5+1)*10 = 60\n",
        "- parameters = (input+1)x output = (10+1)*3 = 33"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCAP_MTaZ86k"
      },
      "source": [
        "## METHOD 2\n",
        "### 2. The Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGVV_v7iZ86k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db09746d-8f68-466f-c236-9dcdf9844911"
      },
      "source": [
        "from tensorflow.keras.models import Model #import class known as models\n",
        "# This returns a tensor\n",
        "inputs = tf.keras.layers.Input(shape=(4,)) # defining input layer and the output of this layer is assigned to input variable\n",
        "# A layer instance is callable on a tensor, and returns a tensor\n",
        "x1 = tf.keras.layers.Dense(5, activation='relu')(inputs) # it has 5 outputs\n",
        "x2 = tf.keras.layers.Dense(10, activation='relu')(x1) \n",
        "outputs = tf.keras.layers.Dense(3, activation='softmax')(x2) # it has 3 outputs sinc ethree classes\n",
        "# we neeed to have probability at the end so tahta we cna choose  the class with the highest probability\n",
        "# This creates a model that includes\n",
        "# the Input layer and three Dense layers\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "# here u have only one input and 1 output but u may also have mutiple input and mtiple output \n",
        "#model = Model(input = [input_tensor, input02...]), outyput = [out_tensor, out02,..])\n",
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 25        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 118\n",
            "Trainable params: 118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOs9R2EGZ86l"
      },
      "source": [
        "## METHOD 3\n",
        "## 3. Model Subclassing \n",
        "advanatge - u can use this approach to define ur own deep learning layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBMw14gXZ86l",
        "outputId": "d61e8a31-469f-4463-c1f4-a626a0e25704"
      },
      "source": [
        "class MyNeuralNetwork(Model): # MyNeuralNetwork is a subclass of Model class\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MyNeuralNetwork, self).__init__(**kwargs)#ask\n",
        "        self.dense1 = tf.keras.layers.Dense(5, activation='relu', )\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(3, activation='softmax')\n",
        "        \n",
        "    def call(self, inputs): # also define a call function \n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)\n",
        "model = MyNeuralNetwork()\n",
        "model.build(input_shape = (None,4))# 4 features\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_neural_network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              multiple                  25        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  60        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  33        \n",
            "=================================================================\n",
            "Total params: 118\n",
            "Trainable params: 118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukhOTfhgZ86l"
      },
      "source": [
        "## Training and Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYOCNLGRZ86m"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) # compiling the model\n",
        "# optimizer is adam\n",
        "# loss is categorical_cross =entropy for muticlass classification probelm\n",
        "# accuracy is used as evaluation matrix\n",
        "# u choose the matrix ur trying to monitor"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_qDbGgnZ86m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafdea04-d9d1-4497-8376-3cbc668fea40"
      },
      "source": [
        "# training the model \n",
        "history = model.fit(X_train, Y_oh_train, validation_data=(X_val,Y_oh_val),batch_size= 64, epochs= 100)\n",
        "#Y_oh_train is binary represnetation of precited va;ues\n",
        "# batch_szine deines the number of samples propogated through teh model\n",
        "# if u have 1000 samples and u ahve a batch sinze of 100, the alrothim takes first 1000 samples to train teh netwrok\n",
        "#epoch is how many times u go through ur training steps\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 191ms/step - loss: 0.2543 - accuracy: 0.9347 - val_loss: 0.2516 - val_accuracy: 0.9189\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2244 - accuracy: 0.9347 - val_loss: 0.2740 - val_accuracy: 0.8919\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2213 - accuracy: 0.9206 - val_loss: 0.2681 - val_accuracy: 0.9189\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2139 - accuracy: 0.9206 - val_loss: 0.2603 - val_accuracy: 0.9189\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2107 - accuracy: 0.9347 - val_loss: 0.2556 - val_accuracy: 0.9189\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2179 - accuracy: 0.9295 - val_loss: 0.2504 - val_accuracy: 0.9189\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2035 - accuracy: 0.9399 - val_loss: 0.2428 - val_accuracy: 0.9459\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.2028 - accuracy: 0.9347 - val_loss: 0.2331 - val_accuracy: 0.9459\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 0.2036 - accuracy: 0.9436 - val_loss: 0.2248 - val_accuracy: 0.9189\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2044 - accuracy: 0.9436 - val_loss: 0.2198 - val_accuracy: 0.9459\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2025 - accuracy: 0.9436 - val_loss: 0.2175 - val_accuracy: 0.9730\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1987 - accuracy: 0.9436 - val_loss: 0.2157 - val_accuracy: 0.9459\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1858 - accuracy: 0.9488 - val_loss: 0.2154 - val_accuracy: 0.9459\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1894 - accuracy: 0.9436 - val_loss: 0.2162 - val_accuracy: 0.9459\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1815 - accuracy: 0.9347 - val_loss: 0.2154 - val_accuracy: 0.9189\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1773 - accuracy: 0.9488 - val_loss: 0.2148 - val_accuracy: 0.9189\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1799 - accuracy: 0.9488 - val_loss: 0.2121 - val_accuracy: 0.9189\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1776 - accuracy: 0.9436 - val_loss: 0.2051 - val_accuracy: 0.9189\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1699 - accuracy: 0.9488 - val_loss: 0.1973 - val_accuracy: 0.9459\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1688 - accuracy: 0.9436 - val_loss: 0.1926 - val_accuracy: 0.9459\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1680 - accuracy: 0.9436 - val_loss: 0.1885 - val_accuracy: 0.9459\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1660 - accuracy: 0.9436 - val_loss: 0.1837 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1538 - accuracy: 0.9488 - val_loss: 0.1805 - val_accuracy: 0.9730\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1537 - accuracy: 0.9488 - val_loss: 0.1820 - val_accuracy: 0.9189\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1522 - accuracy: 0.9629 - val_loss: 0.1868 - val_accuracy: 0.9189\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1524 - accuracy: 0.9577 - val_loss: 0.1866 - val_accuracy: 0.9189\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1516 - accuracy: 0.9577 - val_loss: 0.1825 - val_accuracy: 0.9189\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1501 - accuracy: 0.9577 - val_loss: 0.1767 - val_accuracy: 0.9189\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1396 - accuracy: 0.9629 - val_loss: 0.1647 - val_accuracy: 0.9459\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1404 - accuracy: 0.9577 - val_loss: 0.1559 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1456 - accuracy: 0.9488 - val_loss: 0.1542 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1410 - accuracy: 0.9488 - val_loss: 0.1517 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1405 - accuracy: 0.9436 - val_loss: 0.1546 - val_accuracy: 0.9459\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1369 - accuracy: 0.9577 - val_loss: 0.1625 - val_accuracy: 0.9189\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1338 - accuracy: 0.9577 - val_loss: 0.1667 - val_accuracy: 0.9189\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1249 - accuracy: 0.9681 - val_loss: 0.1632 - val_accuracy: 0.9189\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1292 - accuracy: 0.9577 - val_loss: 0.1538 - val_accuracy: 0.9189\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1249 - accuracy: 0.9718 - val_loss: 0.1435 - val_accuracy: 0.9730\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1271 - accuracy: 0.9577 - val_loss: 0.1388 - val_accuracy: 0.9730\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1267 - accuracy: 0.9629 - val_loss: 0.1369 - val_accuracy: 0.9730\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1326 - accuracy: 0.9577 - val_loss: 0.1374 - val_accuracy: 0.9730\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1156 - accuracy: 0.9629 - val_loss: 0.1424 - val_accuracy: 0.9459\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1186 - accuracy: 0.9718 - val_loss: 0.1494 - val_accuracy: 0.9189\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1192 - accuracy: 0.9577 - val_loss: 0.1537 - val_accuracy: 0.9189\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1208 - accuracy: 0.9577 - val_loss: 0.1531 - val_accuracy: 0.9189\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1192 - accuracy: 0.9577 - val_loss: 0.1409 - val_accuracy: 0.9459\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1113 - accuracy: 0.9718 - val_loss: 0.1298 - val_accuracy: 0.9459\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1087 - accuracy: 0.9629 - val_loss: 0.1250 - val_accuracy: 0.9730\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1125 - accuracy: 0.9577 - val_loss: 0.1230 - val_accuracy: 0.9730\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1100 - accuracy: 0.9577 - val_loss: 0.1213 - val_accuracy: 0.9730\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1081 - accuracy: 0.9629 - val_loss: 0.1197 - val_accuracy: 0.9730\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.1213 - val_accuracy: 0.9459\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1029 - accuracy: 0.9629 - val_loss: 0.1341 - val_accuracy: 0.9459\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1096 - accuracy: 0.9577 - val_loss: 0.1496 - val_accuracy: 0.9189\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1136 - accuracy: 0.9436 - val_loss: 0.1467 - val_accuracy: 0.9189\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1000 - accuracy: 0.9540 - val_loss: 0.1285 - val_accuracy: 0.9459\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1012 - accuracy: 0.9718 - val_loss: 0.1140 - val_accuracy: 0.9459\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0987 - accuracy: 0.9577 - val_loss: 0.1099 - val_accuracy: 0.9730\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1050 - accuracy: 0.9629 - val_loss: 0.1092 - val_accuracy: 0.9730\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1118 - accuracy: 0.9577 - val_loss: 0.1076 - val_accuracy: 0.9730\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1005 - accuracy: 0.9629 - val_loss: 0.1089 - val_accuracy: 0.9459\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1004 - accuracy: 0.9577 - val_loss: 0.1166 - val_accuracy: 0.9459\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 0.0982 - accuracy: 0.9718 - val_loss: 0.1250 - val_accuracy: 0.9459\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.1270 - val_accuracy: 0.9459\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0977 - accuracy: 0.9577 - val_loss: 0.1278 - val_accuracy: 0.9459\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1015 - accuracy: 0.9577 - val_loss: 0.1252 - val_accuracy: 0.9459\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0906 - accuracy: 0.9770 - val_loss: 0.1161 - val_accuracy: 0.9459\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0923 - accuracy: 0.9718 - val_loss: 0.1074 - val_accuracy: 0.9459\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0802 - accuracy: 0.9822 - val_loss: 0.1051 - val_accuracy: 0.9459\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0946 - accuracy: 0.9577 - val_loss: 0.1048 - val_accuracy: 0.9459\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0927 - accuracy: 0.9718 - val_loss: 0.1031 - val_accuracy: 0.9459\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0915 - accuracy: 0.9577 - val_loss: 0.1017 - val_accuracy: 0.9459\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0863 - accuracy: 0.9629 - val_loss: 0.1047 - val_accuracy: 0.9459\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 0.1127 - val_accuracy: 0.9459\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0900 - accuracy: 0.9718 - val_loss: 0.1138 - val_accuracy: 0.9459\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0877 - accuracy: 0.9770 - val_loss: 0.1102 - val_accuracy: 0.9459\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0894 - accuracy: 0.9718 - val_loss: 0.1063 - val_accuracy: 0.9459\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0872 - accuracy: 0.9718 - val_loss: 0.0979 - val_accuracy: 0.9459\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0851 - accuracy: 0.9770 - val_loss: 0.0933 - val_accuracy: 0.9459\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0807 - accuracy: 0.9681 - val_loss: 0.0945 - val_accuracy: 0.9459\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0742 - accuracy: 0.9681 - val_loss: 0.1084 - val_accuracy: 0.9459\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0812 - accuracy: 0.9629 - val_loss: 0.1293 - val_accuracy: 0.9730\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0971 - accuracy: 0.9436 - val_loss: 0.1310 - val_accuracy: 0.9459\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0927 - accuracy: 0.9436 - val_loss: 0.1136 - val_accuracy: 0.9730\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0774 - accuracy: 0.9629 - val_loss: 0.0927 - val_accuracy: 0.9459\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0813 - accuracy: 0.9770 - val_loss: 0.0860 - val_accuracy: 0.9459\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0874 - accuracy: 0.9577 - val_loss: 0.0857 - val_accuracy: 0.9730\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0937 - accuracy: 0.9577 - val_loss: 0.0859 - val_accuracy: 0.9730\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0954 - accuracy: 0.9577 - val_loss: 0.0846 - val_accuracy: 0.9730\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0867 - accuracy: 0.9629 - val_loss: 0.0839 - val_accuracy: 0.9459\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0846 - accuracy: 0.9577 - val_loss: 0.0873 - val_accuracy: 0.9459\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0790 - accuracy: 0.9577 - val_loss: 0.0884 - val_accuracy: 0.9459\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0745 - accuracy: 0.9629 - val_loss: 0.0875 - val_accuracy: 0.9459\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0676 - accuracy: 0.9681 - val_loss: 0.0917 - val_accuracy: 0.9459\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0778 - accuracy: 0.9718 - val_loss: 0.0980 - val_accuracy: 0.9730\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0816 - accuracy: 0.9859 - val_loss: 0.0968 - val_accuracy: 0.9730\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0758 - accuracy: 0.9859 - val_loss: 0.0886 - val_accuracy: 0.9459\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0753 - accuracy: 0.9629 - val_loss: 0.0826 - val_accuracy: 0.9459\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0754 - accuracy: 0.9629 - val_loss: 0.0817 - val_accuracy: 0.9459\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0754 - accuracy: 0.9629 - val_loss: 0.0835 - val_accuracy: 0.9459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ooc-nHwogNX"
      },
      "source": [
        "The validation loss and training loss are decreasing\n",
        "The accuracy of both training and validation sets are increasing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W6TyKAKoxu_"
      },
      "source": [
        "##MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzjbtvNQZ86n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c2067b6-0d02-465e-8b20-df550b1bd486"
      },
      "source": [
        "W = model.get_weights()\n",
        "for ii in range(len(W)//2):\n",
        "    print(\"Layer %d\" %ii)\n",
        "    print('Bias:\\n', W[2*ii + 1])\n",
        "    print('W:\\n', W[2*ii])\n",
        "    print()\n",
        "\n",
        "plt.plot(history.history['loss'], label = \"Train loss\")\n",
        "plt.plot(history.history['val_loss'], label = \"Val loss\")\n",
        "plt.xlabel(\"Epoch (iteration)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'], label = \"Train accuarcy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Val accuarcy\")\n",
        "plt.xlabel(\"Epoch (iteration)\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 0\n",
            "Bias:\n",
            " [ 0.18043059  0.22761948 -0.10304132  0.12070237  0.19484603  0.24604513\n",
            "  0.         -0.08336764 -0.00414739  0.186246    0.18289042 -0.03609409\n",
            "  0.17559665 -0.0239585   0.          0.15110669  0.05617342 -0.01504605\n",
            "  0.1662776  -0.11693136]\n",
            "W:\n",
            " [[-0.28913513  0.09934469  0.17861968 -0.51872754  0.25679228 -0.12540196\n",
            "  -0.40005934  0.50230485  0.02397138  0.30493373 -0.24613711 -0.28527626\n",
            "  -0.14145948 -0.28410873 -0.08979571 -0.28097746 -0.4402156  -0.05148986\n",
            "  -0.39239427 -0.13376601]\n",
            " [ 0.4454043   0.41947198  0.14232889  0.5116105   0.08332233  0.1307456\n",
            "  -0.4607345   0.2009245  -0.20124467  0.17171258  0.20774269  0.18363614\n",
            "   0.41338053 -0.03782277 -0.2339195   0.536769    0.3305136  -0.11918322\n",
            "   0.54269284  0.0267209 ]\n",
            " [-0.0871295   0.271346    0.35237566  0.05518993  0.1665507  -0.3283465\n",
            "  -0.49997914  0.5278964   0.55025613  0.15382117 -0.12994345  0.20261326\n",
            "  -0.05233454  0.40251195  0.20413363  0.26430058 -0.11876926  0.11023407\n",
            "   0.09481361  0.59365714]\n",
            " [-0.21500978  0.48055315  0.09377483 -0.11707589 -0.45552614  0.16634771\n",
            "  -0.26364803  0.44032443  0.18797928 -0.51260674  0.03092299  0.4933645\n",
            "  -0.2460532  -0.30169186 -0.34846497  0.10017015  0.08221057  0.23376928\n",
            "   0.15263444  0.5235626 ]]\n",
            "\n",
            "Layer 1\n",
            "Bias:\n",
            " [ 0.1430827   0.16285273 -0.02488732  0.16257727  0.07322428 -0.06643628\n",
            " -0.07852111  0.          0.12101202  0.         -0.02513384  0.14811094\n",
            " -0.07589203 -0.03329977 -0.09463922  0.02941345  0.17860027 -0.0126258\n",
            " -0.08447282 -0.11242915  0.12816507  0.         -0.16455692  0.01877435\n",
            "  0.          0.1648081   0.03757039  0.2049343   0.          0.09683944\n",
            " -0.10796081  0.03002354  0.10535453  0.1865077  -0.05619978  0.\n",
            "  0.20513447 -0.03102671 -0.00472287  0.13248622 -0.05642324  0.19111592\n",
            "  0.18772614  0.15982662 -0.05107699  0.         -0.01959222  0.15510058\n",
            " -0.0342669   0.09633248]\n",
            "W:\n",
            " [[-4.44929510e-01  1.79754719e-01  4.59680101e-03  2.88960487e-01\n",
            "  -1.87091082e-01 -6.40115142e-02 -9.68492404e-02 -1.65652335e-02\n",
            "   1.82979047e-01 -2.05613077e-02 -3.69282991e-01 -9.13787559e-02\n",
            "  -3.08428109e-01  4.03384343e-02  5.54881468e-02 -4.04893905e-01\n",
            "   3.38258386e-01  1.10102110e-01  1.09399237e-01 -3.25343668e-01\n",
            "  -3.28842998e-01  9.49233770e-04  5.52690364e-02 -2.27824241e-01\n",
            "  -2.02445567e-01  4.21484672e-02  4.21308696e-01  4.15021062e-01\n",
            "   1.57719851e-02  4.03342485e-01 -4.19579335e-02 -3.96191657e-01\n",
            "   4.33685452e-01 -1.34868339e-01 -8.25120229e-03 -1.17784902e-01\n",
            "   3.10624480e-01 -3.88892800e-01  1.25679269e-01  2.00431049e-01\n",
            "   3.86777334e-02  5.58324397e-01  4.27755147e-01  1.16596110e-01\n",
            "  -4.08280134e-01  8.94794464e-02  4.08425257e-02  3.90355200e-01\n",
            "  -3.91003639e-02  9.31667164e-02]\n",
            " [ 2.24774420e-01  8.15057680e-02 -2.21325569e-02  1.45573109e-01\n",
            "   6.09843768e-02  2.93879751e-02  2.79165417e-01 -1.11828089e-01\n",
            "   3.19731861e-01 -1.60413221e-01  1.61819439e-02  6.45550191e-02\n",
            "  -1.09007329e-01 -1.06473841e-01 -1.01191429e-02  2.18495071e-01\n",
            "   6.07146733e-02  6.94381399e-03  3.22885275e-01 -6.10946957e-03\n",
            "   2.31402412e-01 -5.61785698e-03  1.47431776e-01  1.76232144e-01\n",
            "  -1.68318346e-01  3.20770621e-01 -1.43820733e-01  3.07525456e-01\n",
            "  -3.03471088e-03 -3.52992266e-02 -1.97002152e-03  1.07618250e-01\n",
            "  -2.24019229e-01  4.86125261e-01  3.82971555e-01 -2.40114748e-01\n",
            "   3.57036710e-01  2.00052127e-01 -2.83626109e-01  1.21516861e-01\n",
            "   2.65069246e-01  2.75429517e-01  1.84224471e-01  2.23190308e-01\n",
            "   1.08648743e-02 -1.01128519e-01  2.61547565e-01  2.55076379e-01\n",
            "  -2.31693938e-01 -2.79089779e-01]\n",
            " [-6.63211495e-02 -2.44041774e-02  5.05127050e-02  1.24441847e-01\n",
            "  -2.02227309e-01  3.45826775e-01 -1.76595971e-01  2.67053246e-02\n",
            "  -1.69404238e-01 -2.90580541e-01  2.28785291e-01 -3.20569088e-04\n",
            "   3.50015789e-01  1.66331813e-01  3.71010214e-01  3.71842086e-01\n",
            "  -8.08406100e-02  3.78411300e-02  1.93290755e-01  9.09754932e-02\n",
            "  -9.04459972e-03  4.31481898e-02 -3.26166339e-02  2.07323387e-01\n",
            "  -1.23763919e-01  3.76518145e-02 -2.90724095e-02 -7.80402333e-04\n",
            "  -2.12091625e-01  1.48118287e-01 -1.41958937e-01  3.71960402e-01\n",
            "   7.93539956e-02  1.72553390e-01  1.93246171e-01  2.32552052e-01\n",
            "  -2.97233779e-02  3.12144130e-01 -8.33174586e-03 -1.03120223e-01\n",
            "   3.94784898e-01 -2.87992865e-01 -1.03002518e-01  4.63188253e-02\n",
            "  -5.85594922e-02 -1.25354141e-01 -4.06049192e-02 -1.09669939e-01\n",
            "   1.26611009e-01  5.33341505e-02]\n",
            " [-6.62621781e-02  3.65403205e-01  2.37025976e-01  3.01514059e-01\n",
            "  -7.12600797e-02 -3.13648164e-01 -2.81052202e-01  2.88203359e-03\n",
            "   3.22840124e-01  4.34909165e-02 -2.25010753e-01  8.96156877e-02\n",
            "  -1.68460943e-02 -6.69497997e-02  1.01529462e-02 -3.00745398e-01\n",
            "   3.53464603e-01 -2.41155699e-01 -1.44396350e-01  2.33089656e-01\n",
            "  -4.01218176e-01  5.28558791e-02 -2.36927509e-01  5.25450073e-02\n",
            "   2.16755211e-01  2.31936768e-01 -2.11601987e-01  4.12928641e-01\n",
            "  -2.20541269e-01  3.48827928e-01  1.59338072e-01  1.43246010e-01\n",
            "   1.73022106e-01  3.06509554e-01 -4.53292914e-02  1.13518059e-01\n",
            "   1.74133062e-01 -9.35824737e-02 -2.82338768e-01  3.90798450e-01\n",
            "  -1.14203997e-01 -3.47677991e-02  1.05003774e-01  1.69127569e-01\n",
            "  -1.76706120e-01 -2.78178155e-01  1.00170821e-01 -1.13493510e-01\n",
            "   1.63294271e-01  2.60021538e-01]\n",
            " [ 1.16017647e-01  5.02143390e-02 -9.04076099e-02  5.52193165e-01\n",
            "  -6.44772872e-02 -5.26607521e-02 -3.64965916e-01 -4.54400778e-02\n",
            "   1.20889433e-01 -2.50115246e-01 -4.15401608e-01  2.48868555e-01\n",
            "   6.90981895e-02  3.90243088e-03 -2.95744210e-01 -3.13680232e-01\n",
            "   4.06830460e-01 -3.39508474e-01 -1.76926449e-01 -2.29675800e-01\n",
            "   3.22051346e-01 -9.10191238e-02 -1.21686146e-01 -3.52228194e-01\n",
            "  -9.08386111e-02  2.73428321e-01  1.12756386e-01  1.54263347e-01\n",
            "   6.33840263e-02  6.79307282e-02 -4.88136083e-01  5.60140125e-02\n",
            "   4.28924710e-01 -3.66736613e-02 -4.15508211e-01 -2.46529534e-01\n",
            "   5.68365872e-01 -2.13158596e-02  2.64380068e-01  1.64979339e-01\n",
            "  -1.34539932e-01  4.67301875e-01  2.83945560e-01  2.47356609e-01\n",
            "  -1.94409154e-02  1.48532689e-02 -1.84202254e-01  3.36269438e-01\n",
            "   2.48819888e-01  4.05285001e-01]\n",
            " [ 6.14064932e-02  3.29979539e-01 -1.02487013e-01  5.13521023e-02\n",
            "   2.33366758e-01 -3.25866878e-01  4.86239903e-02  9.96426344e-02\n",
            "   3.56209338e-01 -5.93712628e-02 -2.42081627e-01  3.75059247e-02\n",
            "  -3.10688555e-01  1.32996276e-01  5.35397902e-02 -2.91639924e-01\n",
            "   1.06543433e-02 -3.51978779e-01 -8.17936882e-02 -2.88782984e-01\n",
            "  -1.27857432e-01 -1.44456178e-01 -4.52084959e-01 -1.07291803e-01\n",
            "  -1.02256790e-01  2.61595994e-01  3.30352068e-01  3.05531830e-01\n",
            "   1.84214592e-01  2.04509735e-01 -3.36880803e-01 -2.29337555e-03\n",
            "   5.04251838e-01  1.60181120e-01 -1.17058091e-01 -1.62768200e-01\n",
            "   3.84738535e-01  7.87391141e-02 -4.36783722e-03  5.41758180e-01\n",
            "   6.25779852e-02  1.98253602e-01  2.01745138e-01  3.99998486e-01\n",
            "   6.15754426e-02 -1.94944739e-01  2.32128471e-01  1.73834324e-01\n",
            "  -2.26075500e-01 -4.71123345e-02]\n",
            " [ 2.04295248e-01  2.40268171e-01 -2.45851412e-01  1.26901805e-01\n",
            "  -1.78554356e-01  1.01210326e-01  1.55753464e-01 -2.18392149e-01\n",
            "  -2.50115961e-01  2.82042623e-01 -1.99531764e-01 -2.73121893e-02\n",
            "   6.77344799e-02  5.22154570e-02  1.26959383e-01 -1.11069828e-01\n",
            "  -1.21532008e-01  1.03810519e-01  7.80119002e-02  1.55107975e-02\n",
            "  -1.86378658e-01 -1.58351764e-01  2.55415082e-01  2.59573460e-01\n",
            "  -9.64060724e-02  3.98853421e-03  2.52847970e-02  9.01120603e-02\n",
            "  -1.50397152e-01  7.50197768e-02  2.35761344e-01  1.49843842e-01\n",
            "  -6.31116629e-02  1.38020247e-01  5.24974465e-02 -2.05791593e-01\n",
            "   1.65378153e-01 -2.50762403e-01 -1.66097820e-01  1.20488763e-01\n",
            "   7.42009282e-02  2.55049169e-01  1.97891563e-01  2.64932811e-02\n",
            "   5.05797267e-02 -1.23991549e-01  2.15973794e-01 -8.56173038e-02\n",
            "  -8.65945965e-02  3.84423733e-02]\n",
            " [ 2.64046580e-01 -1.42995715e-01  2.92789098e-02 -2.46623605e-01\n",
            "  -1.08053453e-01  2.69242585e-01 -1.36344716e-01 -2.20424086e-01\n",
            "  -2.74086986e-02 -1.63936540e-01  3.69558692e-01 -1.47653490e-01\n",
            "   2.38929242e-01  1.49544984e-01  3.51060688e-01  3.92202616e-01\n",
            "   1.75503150e-01  3.93901825e-01  1.23842083e-01  1.47507563e-01\n",
            "   3.64548177e-01 -2.20805407e-02  1.99120805e-01  3.86911035e-01\n",
            "  -1.97995916e-01  6.75011873e-02  1.63480088e-01 -1.36720851e-01\n",
            "   2.18459964e-03 -1.50559083e-01  3.04067433e-01  2.15900451e-01\n",
            "   2.76962202e-02  4.09339696e-01  7.40373954e-02  1.63104087e-01\n",
            "   2.73230970e-01  5.58222793e-02 -1.60246745e-01 -1.39126420e-01\n",
            "  -8.10144544e-02 -1.85018331e-01 -1.78547904e-01 -2.93601632e-01\n",
            "   1.01011530e-01 -2.31342018e-02 -2.62549639e-01  2.49632686e-01\n",
            "  -2.72615075e-01  2.72611052e-01]\n",
            " [ 4.71197635e-01 -6.11373186e-02  2.28502631e-01 -6.75408542e-02\n",
            "   4.52038050e-02  2.87904590e-01  8.63047317e-03 -6.78091049e-02\n",
            "   1.13268875e-01  2.57603884e-01  2.61539400e-01  3.29428643e-01\n",
            "   3.48902822e-01  1.49268255e-01  8.74293447e-02  3.32299173e-01\n",
            "  -1.08019225e-01  3.08951158e-02  2.09166542e-01  2.55569696e-01\n",
            "   2.88735449e-01 -2.23341092e-01  1.32880762e-01  1.97394583e-02\n",
            "   1.41087323e-01  1.08649611e-01 -6.14627125e-03 -3.17436039e-01\n",
            "  -1.94416478e-01 -8.16076398e-02  2.70427048e-01  3.01229835e-01\n",
            "  -6.57943413e-02  1.38876259e-01 -1.36401191e-01 -2.65824378e-01\n",
            "  -2.63286531e-02  2.77077049e-01 -1.44274130e-01 -2.52002865e-01\n",
            "   9.79771689e-02  8.90401155e-02 -3.04541200e-01 -1.69853076e-01\n",
            "   3.13568950e-01 -1.87328458e-01 -1.07482538e-01 -6.35875463e-02\n",
            "  -1.56620547e-01 -1.72078490e-01]\n",
            " [ 1.75668970e-01  1.70359313e-02 -2.90976226e-01  3.09327990e-01\n",
            "   2.89891541e-01 -2.42575184e-01  5.45652956e-02 -1.98527575e-02\n",
            "  -5.20184338e-02  2.04300195e-01 -3.00741285e-01 -1.40832633e-01\n",
            "  -3.08214515e-01  1.16514198e-01 -3.34488861e-02 -3.97057027e-01\n",
            "   2.81695545e-01 -2.67489552e-01  9.63908806e-02 -6.42326400e-02\n",
            "  -2.98429672e-02 -1.09527066e-01  1.42592983e-02 -3.69368233e-02\n",
            "  -1.08283132e-01  2.85209388e-01  1.66921318e-01  1.60778835e-01\n",
            "   2.91155994e-01  3.16892087e-01 -1.68565646e-01 -3.01496744e-01\n",
            "   3.41749042e-01 -1.20623723e-01 -9.57185030e-02 -1.98650658e-01\n",
            "   2.20536754e-01 -6.18233755e-02  2.58742273e-02  4.53448802e-01\n",
            "  -5.98578006e-02  3.20450217e-01  5.21494210e-01  1.31416515e-01\n",
            "  -4.57014114e-01 -5.47255278e-02 -2.96882875e-02  4.31908667e-01\n",
            "   1.02352127e-01 -2.33282689e-02]\n",
            " [-7.47957304e-02  4.03750777e-01  2.34772965e-01  2.51118779e-01\n",
            "  -1.41408250e-01  1.00521438e-01 -2.55157143e-01 -1.20507523e-01\n",
            "   2.43646532e-01 -1.25797033e-01 -1.22132346e-01 -2.04817191e-01\n",
            "   1.33393571e-01  1.81546122e-01 -4.40283399e-03  1.42612517e-01\n",
            "   1.26683742e-01  3.92711610e-02 -2.52483875e-01  1.35784134e-01\n",
            "  -1.43639550e-01 -2.07164943e-01 -3.55416358e-01  7.97386318e-02\n",
            "   5.36606908e-02  4.40316290e-01  3.49947512e-02  4.00451332e-01\n",
            "  -2.64934391e-01 -5.12953624e-02 -2.42970482e-01  2.81616505e-02\n",
            "   4.51112449e-01  1.61833927e-01  5.31382393e-03 -2.47137859e-01\n",
            "   2.68091530e-01 -2.16073573e-01  2.07125768e-01  3.36621881e-01\n",
            "   5.25072552e-02  4.43504974e-02  4.38530624e-01  3.80057275e-01\n",
            "   1.24904953e-01  8.50045681e-02  2.23923028e-01  3.61312121e-01\n",
            "  -1.70044050e-01  1.34857893e-01]\n",
            " [ 2.17021465e-01 -2.26293057e-02  4.44337949e-02 -5.09972032e-03\n",
            "   1.87741801e-01  7.47082233e-02  3.30635786e-01 -2.61986017e-01\n",
            "   2.55155921e-01  1.52606517e-01  2.45812312e-01  2.57065713e-01\n",
            "  -4.57434775e-03 -2.82202154e-01 -2.82774363e-02  1.93092450e-01\n",
            "  -5.50008975e-02  4.50819254e-01  4.18742061e-01  3.27081531e-01\n",
            "  -3.62917930e-02 -2.89964199e-01  1.47754565e-01  2.76572704e-01\n",
            "   4.86013889e-02 -8.10431913e-02 -2.86226392e-01 -2.78646320e-01\n",
            "   1.04892939e-01  1.69516187e-02  3.58336568e-01  3.14716250e-01\n",
            "   8.81213173e-02  2.27538705e-01  3.36993188e-01 -2.60646105e-01\n",
            "   2.53296345e-01  4.90405053e-01 -2.29703516e-01 -2.18737274e-01\n",
            "   3.32552165e-01 -4.09407258e-01  1.09998316e-01 -1.54751604e-02\n",
            "  -2.59431638e-02  2.36329734e-01  1.84037969e-01 -1.97276205e-01\n",
            "  -8.13400894e-02 -9.69384462e-02]\n",
            " [-2.20118672e-01  4.68544751e-01 -6.65422752e-02  4.77925092e-01\n",
            "  -1.84046164e-01 -2.83357054e-01 -3.97693872e-01  2.08671749e-01\n",
            "   3.11332315e-01 -1.47381082e-01 -1.13423958e-01  6.71331305e-03\n",
            "  -3.93810600e-01  2.08604217e-01  1.19865835e-01 -3.37296009e-01\n",
            "   3.90330762e-01 -1.58440217e-01 -4.09735471e-01 -2.89663225e-01\n",
            "  -2.00358212e-01 -2.32647628e-01 -1.78587452e-01  1.16388761e-01\n",
            "   9.63172913e-02  2.15469807e-01  2.61796296e-01  3.13318640e-01\n",
            "  -4.22956347e-02  9.49969664e-02 -2.13577032e-01  1.78424157e-02\n",
            "   9.48547050e-02  1.94050223e-01 -1.38135031e-01 -6.33577108e-02\n",
            "   3.49754572e-01 -1.03806823e-01  1.57862976e-01  3.71031135e-01\n",
            "  -3.47529113e-01  1.00892102e-02  2.51863390e-01  2.37270504e-01\n",
            "  -3.80979985e-01 -1.82984054e-01 -3.04826647e-01  1.98611274e-01\n",
            "   9.33318734e-02  4.50300217e-01]\n",
            " [-2.21384361e-01 -9.98198539e-02  8.47759321e-02  7.39464983e-02\n",
            "   1.12789184e-01 -2.23015025e-01 -1.98175892e-01  9.32595134e-03\n",
            "  -3.92383002e-02  1.41223252e-01  1.98268771e-01 -1.55741036e-01\n",
            "   1.57276362e-01  1.72900945e-01  2.77299911e-01 -5.58118001e-02\n",
            "  -1.61827758e-01 -1.19639054e-01 -1.88610137e-01  7.15104640e-02\n",
            "  -2.31802464e-01  4.79039252e-02 -1.72708377e-01  1.34198427e-01\n",
            "   2.81038702e-01  1.92273125e-01  2.06415523e-02 -1.35416565e-02\n",
            "   1.71848774e-01  1.71531692e-01 -4.22284715e-02  2.89756078e-02\n",
            "  -2.32651159e-01 -2.31242612e-01 -9.45650339e-02 -8.41682106e-02\n",
            "   4.79902700e-02  2.19886690e-01 -9.44237113e-02  8.24350268e-02\n",
            "   2.86973029e-01  3.00975256e-02  1.92754745e-01 -2.88782895e-01\n",
            "  -2.43054017e-01  1.06642872e-01  4.99565899e-02 -1.51417330e-01\n",
            "   1.96970016e-01  2.92474359e-01]\n",
            " [ 1.64856672e-01 -9.43637490e-02 -2.14637816e-02  2.07976699e-02\n",
            "   2.83467412e-01  1.97583467e-01  9.50386524e-02  2.90396154e-01\n",
            "  -3.64191532e-02 -1.84075415e-01 -1.99487999e-01 -5.78617901e-02\n",
            "   1.61434829e-01 -1.37145981e-01  1.66852772e-02 -1.54726207e-02\n",
            "   2.90989161e-01  2.58361340e-01 -2.19499901e-01  1.42641187e-01\n",
            "   3.38390172e-02  1.35168642e-01 -1.01910934e-01  1.48641467e-02\n",
            "   2.60016799e-01  2.90469944e-01  9.85129774e-02 -1.69522285e-01\n",
            "  -2.54945129e-01  9.33375061e-02 -3.01841795e-02  6.19790554e-02\n",
            "  -8.73192847e-02 -2.42008537e-01 -7.94674754e-02  1.11880302e-01\n",
            "   1.06971830e-01 -7.09271580e-02 -5.09862453e-02  1.00670546e-01\n",
            "   1.91284895e-01  6.40486777e-02 -2.04201296e-01  2.90590405e-01\n",
            "  -1.34942815e-01  1.16007030e-02  2.64579058e-01  7.90157914e-03\n",
            "  -2.54028499e-01  2.87718356e-01]\n",
            " [ 1.07137509e-01  2.72997171e-01 -2.08518684e-01 -2.16994897e-01\n",
            "  -8.98939297e-02  2.70856082e-01  2.21786574e-02 -1.29860476e-01\n",
            "   5.17263971e-02 -1.62801221e-01 -1.64475173e-01 -2.06772596e-01\n",
            "  -1.56301543e-01 -1.43574208e-01 -5.31906672e-02  4.58304659e-02\n",
            "  -1.03233092e-01 -1.45910785e-01 -1.84531003e-01 -6.05963543e-02\n",
            "   1.59165829e-01 -1.25461221e-02  1.79440066e-01  5.06166369e-02\n",
            "  -1.57183111e-02  9.23888236e-02  2.69000810e-02  1.81184128e-01\n",
            "   7.68181682e-03  1.91110909e-01  9.93474498e-02  1.13968812e-01\n",
            "   3.07435123e-03  4.35118496e-01 -1.48705006e-01 -1.37503564e-01\n",
            "  -2.99610402e-02 -7.42665678e-02 -1.23238929e-01  2.01520845e-01\n",
            "  -2.24665273e-02  1.93223268e-01  2.81343937e-01  1.48534730e-01\n",
            "   2.64288515e-01 -2.21280485e-01 -2.09643230e-01  3.43092501e-01\n",
            "  -4.01072800e-02  7.40306303e-02]\n",
            " [-2.57310748e-01 -3.66587341e-02  5.84064610e-02 -1.45673841e-01\n",
            "  -1.84052914e-01 -2.91936278e-01 -2.68368900e-01 -2.41472751e-01\n",
            "  -1.30062357e-01 -8.54012668e-02  3.03155422e-01 -2.39836082e-01\n",
            "   2.80815601e-01 -1.59367934e-01 -3.02763104e-01 -1.96568504e-01\n",
            "  -1.37574241e-01  7.63806626e-02  1.33424848e-01 -9.54850093e-02\n",
            "  -3.27240199e-01  1.87113464e-01 -1.29425302e-01 -3.08436275e-01\n",
            "  -1.40208393e-01  3.91217858e-01 -4.00973484e-02  3.48103642e-01\n",
            "  -1.77458480e-01  7.96127878e-03  2.64524370e-01 -2.96656549e-01\n",
            "   1.13954596e-01  9.64915678e-02  2.32485056e-01 -2.31919810e-01\n",
            "  -4.59235013e-02  2.42629364e-01  2.62229234e-01  3.44068795e-01\n",
            "  -2.29814261e-01  2.04844058e-01  1.91863552e-01  8.96471143e-02\n",
            "   4.65942994e-02  1.19521707e-01 -3.01736891e-01 -2.04857066e-01\n",
            "  -7.08895177e-02  2.74856716e-01]\n",
            " [ 9.57910717e-03 -3.94503713e-01 -2.38099083e-01 -3.12765092e-01\n",
            "   1.95775822e-01 -8.39767419e-03 -1.86632335e-01 -1.13701150e-01\n",
            "   1.04966886e-01 -7.73279816e-02  4.85344380e-02  3.60867918e-01\n",
            "   2.23944262e-01 -1.40514940e-01  1.09979168e-01  7.23111108e-02\n",
            "   2.15368569e-01  3.96497279e-01  1.50480345e-01 -3.05327158e-02\n",
            "   2.85268158e-01 -7.83525407e-02  2.81391777e-02  4.96248417e-02\n",
            "  -2.48308986e-01  1.03677653e-01 -2.85330623e-01  1.76722288e-01\n",
            "   2.17817843e-01 -4.37463492e-01  5.54863736e-02  3.13819975e-01\n",
            "  -3.53486210e-01  5.08613884e-01  2.23804981e-01  1.71484500e-01\n",
            "   8.29363428e-03  1.01744547e-01 -2.48945385e-01  4.28760378e-03\n",
            "   2.83918440e-01 -9.83418822e-02 -3.96962970e-01 -3.27896148e-01\n",
            "  -8.73033702e-02  6.81487024e-02  1.77706275e-02  3.40928167e-01\n",
            "   9.87402499e-02  9.58137512e-02]\n",
            " [ 1.73156783e-01  3.27969283e-01  1.56155869e-01  1.37390122e-01\n",
            "   9.40078497e-02 -1.55238107e-01  1.21683434e-01 -2.68055707e-01\n",
            "   7.85322711e-02 -2.22599104e-01  1.79226026e-01 -3.01029027e-01\n",
            "   2.39819750e-01 -2.46374384e-01  1.08895652e-01  4.18016165e-01\n",
            "  -4.18001413e-02  3.70309085e-01  1.13947824e-01  5.92043921e-02\n",
            "   2.42245182e-01 -1.90795302e-01 -5.95417246e-02  1.05342321e-01\n",
            "   4.26384509e-02 -8.54368210e-02 -1.25384226e-01 -1.07982166e-01\n",
            "  -2.79132158e-01  2.96948045e-01 -1.57831550e-01  4.29212712e-02\n",
            "   2.66074479e-01  2.78400093e-01 -8.60645697e-02 -6.08431697e-02\n",
            "   3.29371661e-01 -8.48949626e-02 -3.25667374e-02  2.39181355e-01\n",
            "   2.55200177e-01  1.87647417e-01  1.69662416e-01  2.01483741e-02\n",
            "   2.59294540e-01 -6.13287091e-02 -1.65192410e-01  1.20412916e-01\n",
            "   2.52962351e-01  4.66653667e-02]\n",
            " [ 2.30013102e-01 -3.33620578e-01 -3.08727175e-01 -6.21721661e-03\n",
            "  -6.39813244e-02  2.07624435e-01  4.08620745e-01 -2.45532483e-01\n",
            "   1.87663361e-04 -2.12715298e-01  2.28535876e-01 -1.42839357e-01\n",
            "   2.49464080e-01 -2.72886395e-01  5.22098802e-02  1.77072868e-01\n",
            "  -3.98730636e-01  7.63322860e-02  1.26559153e-01 -1.16442926e-01\n",
            "  -1.60654902e-01 -1.01287603e-01  2.42081881e-01  1.52970642e-01\n",
            "   1.36351913e-01 -2.57263720e-01  1.68860883e-01 -2.35968783e-01\n",
            "  -2.33255684e-01 -1.69164881e-01 -9.80921611e-02  4.56073254e-01\n",
            "   1.75109878e-01  3.56114149e-01  3.37173432e-01 -2.17982262e-01\n",
            "  -1.03035651e-01  3.13687563e-01  2.66549766e-01  5.47044799e-02\n",
            "   2.98733264e-01 -2.07423270e-01 -2.22003832e-01 -8.64570215e-02\n",
            "   1.77076310e-01 -2.82366216e-01 -2.97741175e-01  2.15378165e-01\n",
            "  -1.80012807e-01 -9.67716724e-02]]\n",
            "\n",
            "Layer 2\n",
            "Bias:\n",
            " [ 0.         -0.0154296  -0.07960846 -0.13252707  0.16869326 -0.02195711\n",
            "  0.19690005 -0.01124118 -0.01252227  0.         -0.09497602  0.\n",
            "  0.14056575  0.05604653 -0.07196222  0.1585305   0.09820461  0.00933517\n",
            "  0.         -0.01054407 -0.00518146 -0.00600465 -0.07763737  0.13574506\n",
            "  0.0309367   0.13285235 -0.00316671  0.         -0.01559198  0.\n",
            "  0.0034567  -0.10022934  0.02250854 -0.01233922 -0.00668701  0.08290068\n",
            "  0.          0.05042497 -0.00837878 -0.01547521 -0.01507652  0.\n",
            "  0.          0.14289424 -0.0217049   0.05372275 -0.00215979  0.\n",
            " -0.01916155  0.139025  ]\n",
            "W:\n",
            " [[ 0.18959428 -0.17749633 -0.14437777 ...  0.13672431 -0.13521609\n",
            "  -0.01533404]\n",
            " [-0.10244298  0.0830958   0.01737299 ...  0.06822111  0.09349439\n",
            "   0.3385448 ]\n",
            " [-0.08682659 -0.14676152 -0.14326267 ... -0.18222573  0.11393929\n",
            "  -0.15053406]\n",
            " ...\n",
            " [-0.04433973 -0.10990892  0.10892916 ... -0.11158206 -0.08009247\n",
            "   0.24837376]\n",
            " [ 0.01015775  0.05390468  0.13956259 ...  0.12026094  0.17750838\n",
            "   0.12228592]\n",
            " [ 0.14448832  0.13267986  0.09341255 ...  0.12143572 -0.19004044\n",
            "   0.33027393]]\n",
            "\n",
            "Layer 3\n",
            "Bias:\n",
            " [-0.04863342  0.09775732 -0.12759806]\n",
            "W:\n",
            " [[-0.16464417  0.22555444 -0.18816072]\n",
            " [-0.19585839 -0.15463382 -0.26232126]\n",
            " [-0.44073117 -0.00918323  0.39204553]\n",
            " [-0.08103078 -0.36049598  0.39789927]\n",
            " [ 0.38575986  0.33489826 -0.52042484]\n",
            " [ 0.00239314 -0.14241517  0.14596231]\n",
            " [ 0.14215012  0.18048564 -0.38560787]\n",
            " [-0.49550584 -0.13171035  0.04959367]\n",
            " [ 0.26826265 -0.26531008 -0.13199075]\n",
            " [-0.10688137  0.23647282  0.00846633]\n",
            " [-0.5230862  -0.18705316  0.11239453]\n",
            " [-0.2070062   0.30315307 -0.22916344]\n",
            " [ 0.15676178  0.08939733 -0.39193702]\n",
            " [ 0.56214    -0.28572142  0.11890285]\n",
            " [-0.05232351  0.18167791  0.439248  ]\n",
            " [ 0.20929053  0.2852226  -0.33713126]\n",
            " [-0.54354125  0.33545512  0.20110321]\n",
            " [-0.06148504 -0.19060645 -0.12073928]\n",
            " [ 0.0480538   0.02727154 -0.12643509]\n",
            " [-0.10556482  0.272997   -0.33252835]\n",
            " [ 0.32890663 -0.1731465  -0.11851853]\n",
            " [ 0.25361365 -0.18430223  0.10302259]\n",
            " [-0.46004432 -0.19280261 -0.07723322]\n",
            " [ 0.2144838   0.06725858 -0.4860478 ]\n",
            " [ 0.42085874 -0.52571857 -0.11468055]\n",
            " [ 0.1565802   0.4197404  -0.4333496 ]\n",
            " [-0.3937098   0.06225371  0.26566592]\n",
            " [ 0.26060435  0.02440417  0.1399233 ]\n",
            " [ 0.30119017 -0.15387954 -0.04998968]\n",
            " [ 0.12171322  0.31584314 -0.17299995]\n",
            " [-0.16265002  0.22066933  0.29259443]\n",
            " [ 0.05289377  0.23647347  0.3091112 ]\n",
            " [ 0.33976895 -0.23555164 -0.02235863]\n",
            " [-0.3221421  -0.18831697  0.23741095]\n",
            " [-0.24645521 -0.06195788 -0.06419316]\n",
            " [-0.41365004  0.18228467  0.27134252]\n",
            " [ 0.13600674  0.21235397  0.29709283]\n",
            " [ 0.22119361 -0.5370135  -0.05908515]\n",
            " [-0.07076483 -0.13589568 -0.15851702]\n",
            " [ 0.09841838 -0.01426956 -0.24087709]\n",
            " [ 0.02311248 -0.39096856 -0.20438181]\n",
            " [-0.06515178  0.13553402 -0.05306911]\n",
            " [ 0.3023183  -0.24296802  0.14364448]\n",
            " [ 0.12065458  0.35960656 -0.5928719 ]\n",
            " [-0.29680973 -0.01778173 -0.14890532]\n",
            " [ 0.36203328 -0.3916379  -0.21678154]\n",
            " [-0.0987801  -0.20906472 -0.1516797 ]\n",
            " [-0.2311053  -0.1011944   0.12051588]\n",
            " [-0.15153454 -0.32407847  0.04715569]\n",
            " [ 0.3957707   0.10498144 -0.32281324]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDNYzKQXpdmJ"
      },
      "source": [
        "The validation and training loss and accuracy r decreasing and increasing respectively\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHcb-bgR3AgF"
      },
      "source": [
        "#MODEL TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVEyphtf2zYJ",
        "outputId": "9248710b-ad31-43db-d538-e1d0343fb877"
      },
      "source": [
        "loss = model.evaluate(X_test, Y_oh_test, verbose=0) #test data needed\n",
        "print('Test loss (cross-entropy and accuracy):',loss)\n",
        "print()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss (cross-entropy and accuracy): [0.04985526204109192, 1.0]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCTnTMgp7icL"
      },
      "source": [
        "**CONCLUSIONS**\n",
        "- The accuracy of test dataset is 100%.\n",
        "- The Categorical cross-entropy is 0.05\n"
      ]
    }
  ]
}